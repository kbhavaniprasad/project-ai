{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind Turbine Energy Output Prediction\n",
    "## Weather-Based Prediction: A Next-Generation Approach to Renewable Energy Management\n",
    "\n",
    "This notebook demonstrates the complete workflow for predicting wind turbine energy output based on weather conditions.\n",
    "\n",
    "### Project Objectives:\n",
    "1. **Energy Production Forecasting** - Predict energy output based on weather forecasts\n",
    "2. **Maintenance Planning** - Schedule maintenance during low wind activity periods\n",
    "3. **Grid Integration** - Balance grid by predicting wind energy availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "Import all necessary libraries for data processing, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Model Persistence\n",
    "import pickle\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Collection - Load Dataset\n",
    "Load the wind turbine dataset and rename columns for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (50530, 5)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>LV ActivePower (kW)</th>\n",
       "      <th>Wind Speed (m/s)</th>\n",
       "      <th>Theoretical_Power_Curve (KWh)</th>\n",
       "      <th>Wind Direction (¬∞)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 01 2018 00:00</td>\n",
       "      <td>380.047791</td>\n",
       "      <td>5.311336</td>\n",
       "      <td>416.328908</td>\n",
       "      <td>259.994904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01 01 2018 00:10</td>\n",
       "      <td>453.769196</td>\n",
       "      <td>5.672167</td>\n",
       "      <td>519.917511</td>\n",
       "      <td>268.641113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01 01 2018 00:20</td>\n",
       "      <td>306.376587</td>\n",
       "      <td>5.216037</td>\n",
       "      <td>390.900016</td>\n",
       "      <td>272.564789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01 01 2018 00:30</td>\n",
       "      <td>419.645905</td>\n",
       "      <td>5.659674</td>\n",
       "      <td>516.127569</td>\n",
       "      <td>271.258087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01 01 2018 00:40</td>\n",
       "      <td>380.650696</td>\n",
       "      <td>5.577941</td>\n",
       "      <td>491.702972</td>\n",
       "      <td>265.674286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date/Time  LV ActivePower (kW)  Wind Speed (m/s)  \\\n",
       "0  01 01 2018 00:00           380.047791          5.311336   \n",
       "1  01 01 2018 00:10           453.769196          5.672167   \n",
       "2  01 01 2018 00:20           306.376587          5.216037   \n",
       "3  01 01 2018 00:30           419.645905          5.659674   \n",
       "4  01 01 2018 00:40           380.650696          5.577941   \n",
       "\n",
       "   Theoretical_Power_Curve (KWh)  Wind Direction (¬∞)  \n",
       "0                     416.328908          259.994904  \n",
       "1                     519.917511          268.641113  \n",
       "2                     390.900016          272.564789  \n",
       "3                     516.127569          271.258087  \n",
       "4                     491.702972          265.674286  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('T1.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current columns:\n",
      "['Date/Time', 'LV ActivePower (kW)', 'Wind Speed (m/s)', 'Theoretical_Power_Curve (KWh)', 'Wind Direction (¬∞)']\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50530 entries, 0 to 50529\n",
      "Data columns (total 5 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Date/Time                      50530 non-null  object \n",
      " 1   LV ActivePower (kW)            50530 non-null  float64\n",
      " 2   Wind Speed (m/s)               50530 non-null  float64\n",
      " 3   Theoretical_Power_Curve (KWh)  50530 non-null  float64\n",
      " 4   Wind Direction (¬∞)             50530 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Rename columns for better understanding\n",
    "# Adjust column names based on your actual dataset structure\n",
    "# Common columns: Wind Speed, Wind Direction, Theoretical Power, Actual Power\n",
    "\n",
    "# Display current column names\n",
    "print(\"Current columns:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Example renaming (modify based on your actual column names)\n",
    "# df.columns = ['Wind_Speed', 'Wind_Direction', 'Theoretical_Power', 'Actual_Power']\n",
    "\n",
    "# Display updated column names\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing - Check for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values Count:\n",
      "Date/Time                        0\n",
      "LV ActivePower (kW)              0\n",
      "Wind Speed (m/s)                 0\n",
      "Theoretical_Power_Curve (KWh)    0\n",
      "Wind Direction (¬∞)               0\n",
      "dtype: int64\n",
      "\n",
      "‚úì No null values found in the dataset!\n",
      "\n",
      "Null Values Percentage:\n",
      "Date/Time                        0.0\n",
      "LV ActivePower (kW)              0.0\n",
      "Wind Speed (m/s)                 0.0\n",
      "Theoretical_Power_Curve (KWh)    0.0\n",
      "Wind Direction (¬∞)               0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(\"Null Values Count:\")\n",
    "null_counts = df.isnull().sum()\n",
    "print(null_counts)\n",
    "\n",
    "# Visualize null values\n",
    "if null_counts.sum() > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    null_counts[null_counts > 0].plot(kind='bar', color='coral')\n",
    "    plt.title('Null Values per Column', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Number of Null Values')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n‚úì No null values found in the dataset!\")\n",
    "\n",
    "# Display percentage of null values\n",
    "print(\"\\nNull Values Percentage:\")\n",
    "print((df.isnull().sum() / len(df)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Handle Missing Data\n",
    "Take care of missing data using appropriate strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original shape: (50530, 5)\n",
      "Current shape: (50530, 5)\n",
      "\n",
      "‚úì Missing data handled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Store original shape\n",
    "original_shape = df.shape\n",
    "\n",
    "# Strategy 1: Drop rows with null values (if very few)\n",
    "# df = df.dropna()\n",
    "\n",
    "# Strategy 2: Fill with mean/median for numerical columns\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "        print(f\"Filled {col} with median value\")\n",
    "\n",
    "# Strategy 3: Fill with mode for categorical columns\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        print(f\"Filled {col} with mode value\")\n",
    "\n",
    "print(f\"\\nOriginal shape: {original_shape}\")\n",
    "print(f\"Current shape: {df.shape}\")\n",
    "print(\"\\n‚úì Missing data handled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Exploratory Data Analysis (EDA)\n",
    "### Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LV ActivePower (kW)</th>\n",
       "      <th>Wind Speed (m/s)</th>\n",
       "      <th>Theoretical_Power_Curve (KWh)</th>\n",
       "      <th>Wind Direction (¬∞)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50530.000000</td>\n",
       "      <td>50530.000000</td>\n",
       "      <td>50530.000000</td>\n",
       "      <td>50530.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1307.684332</td>\n",
       "      <td>7.557952</td>\n",
       "      <td>1492.175463</td>\n",
       "      <td>123.687559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1312.459242</td>\n",
       "      <td>4.227166</td>\n",
       "      <td>1368.018238</td>\n",
       "      <td>93.443736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.471405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.677890</td>\n",
       "      <td>4.201395</td>\n",
       "      <td>161.328167</td>\n",
       "      <td>49.315437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>825.838074</td>\n",
       "      <td>7.104594</td>\n",
       "      <td>1063.776283</td>\n",
       "      <td>73.712978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2482.507568</td>\n",
       "      <td>10.300020</td>\n",
       "      <td>2964.972462</td>\n",
       "      <td>201.696720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3618.732910</td>\n",
       "      <td>25.206011</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>359.997589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LV ActivePower (kW)  Wind Speed (m/s)  Theoretical_Power_Curve (KWh)  \\\n",
       "count         50530.000000      50530.000000                   50530.000000   \n",
       "mean           1307.684332          7.557952                    1492.175463   \n",
       "std            1312.459242          4.227166                    1368.018238   \n",
       "min              -2.471405          0.000000                       0.000000   \n",
       "25%              50.677890          4.201395                     161.328167   \n",
       "50%             825.838074          7.104594                    1063.776283   \n",
       "75%            2482.507568         10.300020                    2964.972462   \n",
       "max            3618.732910         25.206011                    3600.000000   \n",
       "\n",
       "       Wind Direction (¬∞)  \n",
       "count        50530.000000  \n",
       "mean           123.687559  \n",
       "std             93.443736  \n",
       "min              0.000000  \n",
       "25%             49.315437  \n",
       "50%             73.712978  \n",
       "75%            201.696720  \n",
       "max            359.997589  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Data Visualization\n",
    "### Correlation Analysis with Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '01 01 2018 00:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate correlation matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create heatmap\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\k bhavaniprasad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:11076\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11074\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11075\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11076\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11079\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32mc:\\Users\\k bhavaniprasad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:2002\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2001\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 2002\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   2004\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\k bhavaniprasad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1713\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1711\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1713\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1714\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1715\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\k bhavaniprasad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1772\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1771\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1772\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1773\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '01 01 2018 00:00'"
     ]
    }
   ],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            fmt='.2f',\n",
    "            square=True,\n",
    "            linewidths=1,\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap - Wind Turbine Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"- Strong positive correlation indicates features move together\")\n",
    "print(\"- Wind Direction typically shows weak correlation with Power Generated\")\n",
    "print(\"- Wind Speed shows strong positive correlation with Power Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of numerical features\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "n_cols = len(numerical_cols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=(n_cols + 1) // 2, ncols=2, figsize=(15, 4 * ((n_cols + 1) // 2)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    axes[idx].hist(df[col], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Hide extra subplots if odd number of columns\n",
    "for idx in range(n_cols, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots - Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairplot for key features\n",
    "# Adjust column names based on your dataset\n",
    "sns.pairplot(df, diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "plt.suptitle('Pairwise Relationships - Wind Turbine Features', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Feature Engineering\n",
    "### Identify Independent (X) and Dependent (y) Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "# Adjust based on your actual column names\n",
    "# Typically, we want to predict Actual Power Generated\n",
    "\n",
    "# Example: If your target column is the last column\n",
    "target_column = df.columns[-1]  # Adjust this based on your dataset\n",
    "\n",
    "# Or specify explicitly:\n",
    "# target_column = 'Actual_Power'  # Replace with your actual target column name\n",
    "\n",
    "print(f\"Target Variable: {target_column}\")\n",
    "print(f\"\\nFeature Variables:\")\n",
    "\n",
    "# Select features (all columns except target)\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "print(X.columns.tolist())\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding (if categorical features exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    print(\"Categorical columns found:\", categorical_cols.tolist())\n",
    "    \n",
    "    # Apply Label Encoding\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "        print(f\"‚úì Encoded {col}\")\n",
    "    \n",
    "    print(\"\\n‚úì Label encoding completed!\")\n",
    "else:\n",
    "    print(\"‚úì No categorical columns found - all features are numerical!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding (Alternative approach for categorical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you prefer One-Hot Encoding instead of Label Encoding, use this:\n",
    "# X = pd.get_dummies(X, drop_first=True)\n",
    "# print(f\"Features after One-Hot Encoding: {X.shape}\")\n",
    "# print(X.columns.tolist())\n",
    "\n",
    "print(\"Note: Using Label Encoding by default. Uncomment above code for One-Hot Encoding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Feature Scaling\n",
    "Normalize features for better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame for better visualization\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(\"‚úì Feature scaling completed!\")\n",
    "print(\"\\nScaled Features - First 5 rows:\")\n",
    "print(X_scaled.head())\n",
    "\n",
    "print(\"\\nScaled Features Statistics:\")\n",
    "print(X_scaled.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Train-Test Split\n",
    "Split data into training (80%) and testing (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data Split Summary:\")\n",
    "print(f\"Training set size: {X_train.shape[0]} samples ({(X_train.shape[0]/len(df))*100:.1f}%)\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples ({(X_test.shape[0]/len(df))*100:.1f}%)\")\n",
    "print(f\"\\nFeatures: {X_train.shape[1]}\")\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Model Building\n",
    "### Model 1: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr_train = lr_model.predict(X_train)\n",
    "y_pred_lr_test = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "lr_train_r2 = r2_score(y_train, y_pred_lr_train)\n",
    "lr_test_r2 = r2_score(y_test, y_pred_lr_test)\n",
    "lr_mae = mean_absolute_error(y_test, y_pred_lr_test)\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lr_test))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LINEAR REGRESSION MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training R¬≤ Score: {lr_train_r2:.4f}\")\n",
    "print(f\"Testing R¬≤ Score: {lr_test_r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {lr_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {lr_rmse:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Random Forest model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf_train = rf_model.predict(X_train)\n",
    "y_pred_rf_test = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "rf_train_r2 = r2_score(y_train, y_pred_rf_train)\n",
    "rf_test_r2 = r2_score(y_test, y_pred_rf_test)\n",
    "rf_mae = mean_absolute_error(y_test, y_pred_rf_test)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf_test))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST REGRESSION MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training R¬≤ Score: {rf_train_r2:.4f}\")\n",
    "print(f\"Testing R¬≤ Score: {rf_test_r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {rf_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rf_rmse:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Decision Tree model\n",
    "dt_model = DecisionTreeRegressor(\n",
    "    random_state=42,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt_train = dt_model.predict(X_train)\n",
    "y_pred_dt_test = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "dt_train_r2 = r2_score(y_train, y_pred_dt_train)\n",
    "dt_test_r2 = r2_score(y_test, y_pred_dt_test)\n",
    "dt_mae = mean_absolute_error(y_test, y_pred_dt_test)\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_test, y_pred_dt_test))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DECISION TREE REGRESSION MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training R¬≤ Score: {dt_train_r2:.4f}\")\n",
    "print(f\"Testing R¬≤ Score: {dt_test_r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {dt_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {dt_rmse:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Model Comparison\n",
    "Compare all three models to select the best performer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Decision Tree'],\n",
    "    'Train R¬≤ Score': [lr_train_r2, rf_train_r2, dt_train_r2],\n",
    "    'Test R¬≤ Score': [lr_test_r2, rf_test_r2, dt_test_r2],\n",
    "    'MAE': [lr_mae, rf_mae, dt_mae],\n",
    "    'RMSE': [lr_rmse, rf_rmse, dt_rmse]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(model_comparison.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identify best model based on Test R¬≤ Score\n",
    "best_model_idx = model_comparison['Test R¬≤ Score'].idxmax()\n",
    "best_model_name = model_comparison.loc[best_model_idx, 'Model']\n",
    "best_r2 = model_comparison.loc[best_model_idx, 'Test R¬≤ Score']\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Test R¬≤ Score: {best_r2:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: R¬≤ Scores\n",
    "x_pos = np.arange(len(model_comparison))\n",
    "width = 0.35\n",
    "axes[0, 0].bar(x_pos - width/2, model_comparison['Train R¬≤ Score'], width, label='Train R¬≤', color='skyblue')\n",
    "axes[0, 0].bar(x_pos + width/2, model_comparison['Test R¬≤ Score'], width, label='Test R¬≤', color='coral')\n",
    "axes[0, 0].set_xlabel('Models', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('R¬≤ Score', fontweight='bold')\n",
    "axes[0, 0].set_title('R¬≤ Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xticks(x_pos)\n",
    "axes[0, 0].set_xticklabels(model_comparison['Model'], rotation=15)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: MAE Comparison\n",
    "axes[0, 1].bar(model_comparison['Model'], model_comparison['MAE'], color='lightgreen')\n",
    "axes[0, 1].set_xlabel('Models', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Mean Absolute Error', fontweight='bold')\n",
    "axes[0, 1].set_title('MAE Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].tick_params(axis='x', rotation=15)\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: RMSE Comparison\n",
    "axes[1, 0].bar(model_comparison['Model'], model_comparison['RMSE'], color='plum')\n",
    "axes[1, 0].set_xlabel('Models', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Root Mean Squared Error', fontweight='bold')\n",
    "axes[1, 0].set_title('RMSE Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].tick_params(axis='x', rotation=15)\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4: Overall Performance Heatmap\n",
    "comparison_normalized = model_comparison.copy()\n",
    "comparison_normalized['MAE'] = 1 - (comparison_normalized['MAE'] / comparison_normalized['MAE'].max())\n",
    "comparison_normalized['RMSE'] = 1 - (comparison_normalized['RMSE'] / comparison_normalized['RMSE'].max())\n",
    "heatmap_data = comparison_normalized[['Test R¬≤ Score', 'MAE', 'RMSE']].T\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "            xticklabels=model_comparison['Model'], \n",
    "            yticklabels=['Test R¬≤', 'MAE (norm)', 'RMSE (norm)'],\n",
    "            ax=axes[1, 1], cbar_kws={'label': 'Performance Score'})\n",
    "axes[1, 1].set_title('Normalized Performance Heatmap', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Actual vs Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create actual vs predicted plots for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "models_pred = [\n",
    "    ('Linear Regression', y_pred_lr_test, lr_test_r2),\n",
    "    ('Random Forest', y_pred_rf_test, rf_test_r2),\n",
    "    ('Decision Tree', y_pred_dt_test, dt_test_r2)\n",
    "]\n",
    "\n",
    "for idx, (name, y_pred, r2) in enumerate(models_pred):\n",
    "    axes[idx].scatter(y_test, y_pred, alpha=0.6, s=30)\n",
    "    axes[idx].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                   'r--', lw=2, label='Perfect Prediction')\n",
    "    axes[idx].set_xlabel('Actual Values', fontweight='bold')\n",
    "    axes[idx].set_ylabel('Predicted Values', fontweight='bold')\n",
    "    axes[idx].set_title(f'{name}\\nR¬≤ = {r2:.4f}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create residual plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, (name, y_pred, r2) in enumerate(models_pred):\n",
    "    residuals = y_test - y_pred\n",
    "    axes[idx].scatter(y_pred, residuals, alpha=0.6, s=30)\n",
    "    axes[idx].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "    axes[idx].set_xlabel('Predicted Values', fontweight='bold')\n",
    "    axes[idx].set_ylabel('Residuals', fontweight='bold')\n",
    "    axes[idx].set_title(f'{name} - Residual Plot', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Good models show residuals randomly scattered around zero with no clear pattern.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Save the Best Model\n",
    "Save the best performing model along with the scaler for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "if best_model_name == 'Linear Regression':\n",
    "    best_model = lr_model\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_model = rf_model\n",
    "else:\n",
    "    best_model = dt_model\n",
    "\n",
    "# Save the model\n",
    "model_filename = 'Flask/power_prediction.sav'\n",
    "pickle.dump(best_model, open(model_filename, 'wb'))\n",
    "print(f\"‚úì Best model ({best_model_name}) saved as '{model_filename}'\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_filename = 'Flask/scaler.sav'\n",
    "pickle.dump(scaler, open(scaler_filename, 'wb'))\n",
    "print(f\"‚úì Scaler saved as '{scaler_filename}'\")\n",
    "\n",
    "# Save feature names for reference\n",
    "feature_names_filename = 'Flask/feature_names.pkl'\n",
    "pickle.dump(X.columns.tolist(), open(feature_names_filename, 'wb'))\n",
    "print(f\"‚úì Feature names saved as '{feature_names_filename}'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL DEPLOYMENT READY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Test R¬≤ Score: {best_r2:.4f}\")\n",
    "print(f\"Features: {len(X.columns)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Test the Saved Model\n",
    "Load and test the saved model to ensure it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = pickle.load(open(model_filename, 'rb'))\n",
    "loaded_scaler = pickle.load(open(scaler_filename, 'rb'))\n",
    "\n",
    "# Test with a sample from test set\n",
    "sample_idx = 0\n",
    "sample_input = X_test.iloc[sample_idx:sample_idx+1]\n",
    "actual_output = y_test.iloc[sample_idx]\n",
    "\n",
    "# Make prediction\n",
    "predicted_output = loaded_model.predict(sample_input)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE PREDICTION TEST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input Features: {sample_input.values[0]}\")\n",
    "print(f\"Actual Power Output: {actual_output:.2f}\")\n",
    "print(f\"Predicted Power Output: {predicted_output:.2f}\")\n",
    "print(f\"Prediction Error: {abs(actual_output - predicted_output):.2f}\")\n",
    "print(f\"Accuracy: {(1 - abs(actual_output - predicted_output) / actual_output) * 100:.2f}%\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úì Model loaded and tested successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "### Project Achievements:\n",
    "1. ‚úì Successfully loaded and preprocessed wind turbine dataset\n",
    "2. ‚úì Performed comprehensive exploratory data analysis\n",
    "3. ‚úì Trained and evaluated three regression models\n",
    "4. ‚úì Identified the best performing model\n",
    "5. ‚úì Saved the model for deployment in Flask application\n",
    "\n",
    "### Key Insights:\n",
    "- Wind speed shows strong correlation with power output\n",
    "- Wind direction typically has minimal impact on power generation\n",
    "- Machine learning models can accurately predict turbine output\n",
    "\n",
    "### Next Steps:\n",
    "1. Deploy the model using Flask web application\n",
    "2. Create user-friendly interface for predictions\n",
    "3. Integrate with real-time weather data APIs\n",
    "4. Monitor model performance in production\n",
    "\n",
    "### Business Applications:\n",
    "- **Energy Forecasting**: Predict production for better grid management\n",
    "- **Maintenance Planning**: Schedule maintenance during low-wind periods\n",
    "- **Revenue Optimization**: Optimize energy pricing based on predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
